{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6528\n",
      "[39.         32.         12.         68.         35.         77.\n",
      " 12.         21.         10.         10.33333333  3.96194014  8.\n",
      " 10.        ]\n",
      "[24.         15.          8.         31.          6.         39.\n",
      "  5.         14.         10.          9.57142857  2.14919697 11.\n",
      "  9.        ]\n",
      "[33.         26.          5.         60.         22.         59.\n",
      "  8.         21.         11.          7.66666667  1.3662601   7.\n",
      "  4.        ]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.pkl\",'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "random.seed(1)\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state = 1)\n",
    "print(len(data))\n",
    "print(train_data[0][0])\n",
    "print(test_data[0][0])\n",
    "print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensors(data_list):\n",
    "    # create tensor that is compatible to load and train in the language model\n",
    "    ds = {}\n",
    "    keys = ['skills','subtests','questions','answers','y']\n",
    "    for key in keys:\n",
    "        ds[key] = []\n",
    "    \n",
    "    for entry in data_list:\n",
    "        ds['skills'].append(entry[0])\n",
    "        ds['subtests'].append(entry[1])\n",
    "        ds['questions'].append(entry[2])\n",
    "        ds['answers'].append(entry[3])\n",
    "        ds['y'].append(entry[4])\n",
    "    \n",
    "    ds['skills'] = torch.tensor(ds['skills']).type(torch.float)\n",
    "    ds['subtests'] = torch.tensor(ds['subtests'])\n",
    "    ds['questions'] = torch.tensor(ds['questions'])\n",
    "    ds['answers'] = torch.tensor(ds['answers'])\n",
    "    ds['y'] = torch.tensor(ds['y']).type(torch.float)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self, sentence_dim, skill_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.skill_dim = skill_dim\n",
    "        self.fc_test = nn.Linear(768,sentence_dim)\n",
    "        self.fc_question = nn.Linear(768,sentence_dim)\n",
    "        self.fc_answer = nn.Linear(768,sentence_dim)\n",
    "        self.fc_skill = nn.Linear(skill_dim,skill_dim*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(3*sentence_dim+skill_dim*2,128)\n",
    "        self.out = nn.Linear(128,1)\n",
    "    \n",
    "    def forward(self, skills,test,question,answer):\n",
    "        x1 = self.fc_skill(skills[:,:skill_dim])\n",
    "        x2 = self.fc_test(test)\n",
    "        x3 = self.fc_question(question)\n",
    "        x4 = self.fc_answer(answer)\n",
    "        x = torch.cat((x1,x2,x3,x4),dim=1)\n",
    "        x = self.fc2(self.relu(x))\n",
    "        pred = self.out(self.relu(x))\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, skill_dim):\n",
    "        super().__init__()\n",
    "        self.fc_skill = nn.Linear(skill_dim,skill_dim*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(skill_dim*2,128)\n",
    "        self.out = nn.Linear(128,1)\n",
    "        \n",
    "    def forward(self, skills):\n",
    "        x1 = self.fc_skill(skills)\n",
    "        x = self.fc2(self.relu(x1))\n",
    "        pred = self.out(self.relu(x))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(preds, Y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i, value in enumerate(rounded_preds):\n",
    "        if value == Y[i] and value == 1:\n",
    "            TP += 1\n",
    "        elif value == Y[i] and value == 0:\n",
    "            TN += 1\n",
    "        elif value != Y[i] and value == 0:\n",
    "            FN += 1\n",
    "        elif value != Y[i] and value == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            print(value,Y[i])\n",
    "    print(f'TP: {TP}\\tFN: {FN}')\n",
    "    print(f'FP: {FP}\\tTN: {TN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision(preds,y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "#     print((rounded_preds==1).sum())\n",
    "#     print((y==1).sum())\n",
    "    return precision_score(y,rounded_preds)\n",
    "\n",
    "def recall(preds,y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "    return recall_score(y,rounded_preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(data['skills'],data['subtests'],data['questions'],data['answers']).squeeze(1)\n",
    "\n",
    "    loss = criterion(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    acc = binary_accuracy(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "#     epoch_loss += loss.item()\n",
    "#     epoch_acc += acc.item()\n",
    "#     print(loss)\n",
    "#     print(acc)\n",
    "    return loss,acc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion, matrix=False):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(data['skills'],data['subtests'],data['questions'],data['answers']).squeeze(1)\n",
    "        \n",
    "#         print('eval pred',predictions)\n",
    "\n",
    "        loss = criterion(predictions, data['y'])\n",
    "#         print('eval1',data[4])\n",
    "#         print('eval',(data[4]==0).sum())\n",
    "        acc = binary_accuracy(predictions, data['y'])\n",
    "        \n",
    "        prec = precision(predictions, data['y'])\n",
    "        \n",
    "        rec = recall(predictions, data['y'])\n",
    "        \n",
    "        confusion_matrix(predictions, data['y'])\n",
    "        \n",
    "#         print(f\"Number of positives: {(data[4]==1).sum()}\")\n",
    "#         print(f\"Number of negatives: {(data[4]==0).sum()}\")\n",
    "\n",
    "        \n",
    "    return loss, acc, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "TP: 679\tFN: 14\n",
      "FP: 587\tTN: 26\n",
      "\tTrain Loss: 0.763 | Train Acc: 45.00%\n",
      "\t Val. Loss: 0.687 |  Val. Acc: 53.98%\n",
      "precision:  0.5363349131121643\n",
      "recall:  0.9797979797979798\n",
      "f1 = 0.6932108218478815\n",
      "Epoch: 25\n",
      "TP: 489\tFN: 204\n",
      "FP: 253\tTN: 360\n",
      "\tTrain Loss: 0.590 | Train Acc: 68.88%\n",
      "\t Val. Loss: 0.627 |  Val. Acc: 65.01%\n",
      "precision:  0.6590296495956873\n",
      "recall:  0.7056277056277056\n",
      "f1 = 0.6815331010452962\n",
      "Epoch: 50\n",
      "TP: 517\tFN: 176\n",
      "FP: 270\tTN: 343\n",
      "\tTrain Loss: 0.577 | Train Acc: 70.28%\n",
      "\t Val. Loss: 0.608 |  Val. Acc: 65.85%\n",
      "precision:  0.6569250317662008\n",
      "recall:  0.746031746031746\n",
      "f1 = 0.6986486486486487\n",
      "Epoch: 75\n",
      "TP: 527\tFN: 166\n",
      "FP: 260\tTN: 353\n",
      "\tTrain Loss: 0.568 | Train Acc: 70.99%\n",
      "\t Val. Loss: 0.601 |  Val. Acc: 67.38%\n",
      "precision:  0.6696315120711563\n",
      "recall:  0.7604617604617605\n",
      "f1 = 0.7121621621621621\n",
      "Epoch: 100\n",
      "TP: 521\tFN: 172\n",
      "FP: 241\tTN: 372\n",
      "\tTrain Loss: 0.557 | Train Acc: 71.47%\n",
      "\t Val. Loss: 0.593 |  Val. Acc: 68.38%\n",
      "precision:  0.6837270341207349\n",
      "recall:  0.7518037518037518\n",
      "f1 = 0.7161512027491409\n",
      "Epoch: 125\n",
      "TP: 527\tFN: 166\n",
      "FP: 235\tTN: 378\n",
      "\tTrain Loss: 0.547 | Train Acc: 71.85%\n",
      "\t Val. Loss: 0.592 |  Val. Acc: 69.30%\n",
      "precision:  0.6916010498687664\n",
      "recall:  0.7604617604617605\n",
      "f1 = 0.7243986254295532\n",
      "Epoch: 150\n",
      "TP: 522\tFN: 171\n",
      "FP: 229\tTN: 384\n",
      "\tTrain Loss: 0.540 | Train Acc: 72.06%\n",
      "\t Val. Loss: 0.594 |  Val. Acc: 69.37%\n",
      "precision:  0.6950732356857523\n",
      "recall:  0.7532467532467533\n",
      "f1 = 0.7229916897506925\n",
      "Epoch: 175\n",
      "TP: 520\tFN: 173\n",
      "FP: 229\tTN: 384\n",
      "\tTrain Loss: 0.535 | Train Acc: 72.41%\n",
      "\t Val. Loss: 0.599 |  Val. Acc: 69.22%\n",
      "precision:  0.6942590120160214\n",
      "recall:  0.7503607503607503\n",
      "f1 = 0.7212205270457697\n",
      "Epoch: 200\n",
      "TP: 539\tFN: 154\n",
      "FP: 251\tTN: 362\n",
      "\tTrain Loss: 0.530 | Train Acc: 72.85%\n",
      "\t Val. Loss: 0.604 |  Val. Acc: 68.99%\n",
      "precision:  0.6822784810126582\n",
      "recall:  0.7777777777777778\n",
      "f1 = 0.7269049224544842\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 225\n",
    "ep_log_interval = 25\n",
    "lrn_rate = 0.001\n",
    "sentence_dim = 64\n",
    "skill_dim = 13\n",
    "dropout = 0.1\n",
    "\n",
    "net = BertModel(sentence_dim, skill_dim, dropout)\n",
    "criterion = nn.BCEWithLogitsLoss() #BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "train_ds = create_tensors(train_data)\n",
    "test_ds = create_tensors(test_data)\n",
    "\n",
    "f1_max = [0,0]\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss, train_acc = train(net,train_ds,optimizer,criterion)\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        valid_loss, valid_acc, prec, rec = evaluate(net,test_ds,criterion,matrix=True)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print('precision: ', prec)\n",
    "        print('recall: ', rec)\n",
    "        try:\n",
    "            f1 = 2*(prec*rec)/(prec+rec)\n",
    "            print(f\"f1 = {f1}\")\n",
    "            if f1 > f1_max[0]:\n",
    "                f1_max[0] = f1\n",
    "                f1_max[1] = epoch\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "ig = IntegratedGradients(net)\n",
    "test_ds['skills'].requires_grad_()\n",
    "test_ds['subtests'].requires_grad_()\n",
    "test_ds['questions'].requires_grad_()\n",
    "test_ds['answers'].requires_grad_()\n",
    "\n",
    "\n",
    "attr,delta = ig.attribute((test_ds['skills'],test_ds['subtests'],test_ds['questions'],test_ds['answers'])\\\n",
    "                          ,return_convergence_delta=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5265816  -0.49626047  0.84698583 ... -0.00767463  0.1430453\n",
      "  -0.25636414]\n",
      " [ 1.61411816 -0.51874121  1.61200896 ...  0.00724994 -0.46907122\n",
      "  -0.17645631]\n",
      " [ 1.30944467 -0.97551188  0.86327808 ... -0.00488267 -0.06518743\n",
      "  -0.15018251]\n",
      " ...\n",
      " [ 1.10073395 -0.59946687  0.37022665 ...  0.00441633  0.23832301\n",
      "  -0.1423885 ]\n",
      " [ 0.83878228 -0.23837369  1.22685449 ... -0.01229502  0.05446317\n",
      "  -0.11445141]\n",
      " [ 0.72683366 -1.85246585  1.21836149 ...  0.01089549 -0.14972178\n",
      "   0.02424212]]\n"
     ]
    }
   ],
   "source": [
    "attr = attr[0].detach().numpy()\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Feature Importances\n",
      "G3.PPVT.Vocab.raw :  0.914\n",
      "G3.Elision.PA.raw :  -1.001\n",
      "G3.Syn.GramCorrect.raw :  0.869\n",
      "G3.TOWRE.SWE.raw :  0.390\n",
      "G3.TOWRE.PDE.raw :  0.807\n",
      "G3.WordID.raw :  2.793\n",
      "G3.OL.Spell.Total :  0.263\n",
      "G3.OL.OrthoChoice.1.2.Total :  -0.288\n",
      "G3.DigitSpan.raw :  0.192\n",
      "text_depth_avg :  -0.146\n",
      "text_depth_stdev :  -0.049\n",
      "question_depth :  -0.058\n",
      "answer_depth :  -0.029\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# attr = attr[0].detach().numpy()\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
    "    print(title)\n",
    "    for i in range(len(feature_names)):\n",
    "        print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.bar(x_pos, importances, align='center')\n",
    "        plt.xticks(x_pos, feature_names, rotation='vertical')\n",
    "        plt.xlabel(axis_title)\n",
    "        plt.title(title)\n",
    "visualize_importances(feature_names+['text_depth_avg','text_depth_stdev','question_depth','answer_depth',], np.mean(attr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7234332425068118, 125]\n"
     ]
    }
   ],
   "source": [
    "print(f1_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "TP: 0\tFN: 718\n",
      "FP: 0\tTN: 588\n",
      "\tTrain Loss: 1.269 | Train Acc: 45.46%\n",
      "\t Val. Loss: 1.026 |  Val. Acc: 45.02%\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1 = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bnie/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-23-3d7362532acf>:26: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1 = 2*(prec*rec)/(prec+rec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\n",
      "TP: 628\tFN: 90\n",
      "FP: 412\tTN: 176\n",
      "\tTrain Loss: 0.649 | Train Acc: 62.79%\n",
      "\t Val. Loss: 0.655 |  Val. Acc: 61.56%\n",
      "precision:  0.6038461538461538\n",
      "recall:  0.8746518105849582\n",
      "f1 = 0.714448236632537\n",
      "Epoch: 50\n",
      "TP: 525\tFN: 193\n",
      "FP: 274\tTN: 314\n",
      "\tTrain Loss: 0.615 | Train Acc: 66.47%\n",
      "\t Val. Loss: 0.628 |  Val. Acc: 64.24%\n",
      "precision:  0.6570713391739674\n",
      "recall:  0.7311977715877437\n",
      "f1 = 0.6921555702043507\n",
      "Epoch: 75\n",
      "TP: 542\tFN: 176\n",
      "FP: 262\tTN: 326\n",
      "\tTrain Loss: 0.592 | Train Acc: 68.67%\n",
      "\t Val. Loss: 0.610 |  Val. Acc: 66.46%\n",
      "precision:  0.6741293532338308\n",
      "recall:  0.754874651810585\n",
      "f1 = 0.7122207621550591\n",
      "Epoch: 100\n",
      "TP: 543\tFN: 175\n",
      "FP: 235\tTN: 353\n",
      "\tTrain Loss: 0.577 | Train Acc: 70.62%\n",
      "\t Val. Loss: 0.598 |  Val. Acc: 68.61%\n",
      "precision:  0.6979434447300771\n",
      "recall:  0.7562674094707521\n",
      "f1 = 0.7259358288770053\n",
      "Epoch: 125\n",
      "TP: 547\tFN: 171\n",
      "FP: 225\tTN: 363\n",
      "\tTrain Loss: 0.567 | Train Acc: 71.51%\n",
      "\t Val. Loss: 0.588 |  Val. Acc: 69.68%\n",
      "precision:  0.7085492227979274\n",
      "recall:  0.7618384401114207\n",
      "f1 = 0.7342281879194631\n",
      "Epoch: 150\n",
      "TP: 538\tFN: 180\n",
      "FP: 208\tTN: 380\n",
      "\tTrain Loss: 0.561 | Train Acc: 71.43%\n",
      "\t Val. Loss: 0.582 |  Val. Acc: 70.29%\n",
      "precision:  0.7211796246648794\n",
      "recall:  0.7493036211699164\n",
      "f1 = 0.7349726775956283\n",
      "Epoch: 175\n",
      "TP: 530\tFN: 188\n",
      "FP: 207\tTN: 381\n",
      "\tTrain Loss: 0.554 | Train Acc: 71.81%\n",
      "\t Val. Loss: 0.578 |  Val. Acc: 69.75%\n",
      "precision:  0.7191316146540027\n",
      "recall:  0.7381615598885793\n",
      "f1 = 0.7285223367697593\n",
      "Epoch: 200\n",
      "TP: 534\tFN: 184\n",
      "FP: 209\tTN: 379\n",
      "\tTrain Loss: 0.547 | Train Acc: 72.00%\n",
      "\t Val. Loss: 0.578 |  Val. Acc: 69.91%\n",
      "precision:  0.7187079407806191\n",
      "recall:  0.7437325905292479\n",
      "f1 = 0.731006160164271\n",
      "Epoch: 225\n",
      "TP: 545\tFN: 173\n",
      "FP: 221\tTN: 367\n",
      "\tTrain Loss: 0.542 | Train Acc: 72.27%\n",
      "\t Val. Loss: 0.580 |  Val. Acc: 69.83%\n",
      "precision:  0.7114882506527415\n",
      "recall:  0.7590529247910863\n",
      "f1 = 0.7345013477088949\n",
      "Epoch: 250\n",
      "TP: 548\tFN: 170\n",
      "FP: 228\tTN: 360\n",
      "\tTrain Loss: 0.537 | Train Acc: 72.44%\n",
      "\t Val. Loss: 0.583 |  Val. Acc: 69.53%\n",
      "precision:  0.7061855670103093\n",
      "recall:  0.7632311977715878\n",
      "f1 = 0.7336010709504684\n",
      "Epoch: 275\n",
      "TP: 534\tFN: 184\n",
      "FP: 228\tTN: 360\n",
      "\tTrain Loss: 0.532 | Train Acc: 72.73%\n",
      "\t Val. Loss: 0.585 |  Val. Acc: 68.45%\n",
      "precision:  0.7007874015748031\n",
      "recall:  0.7437325905292479\n",
      "f1 = 0.7216216216216216\n",
      "Epoch: 300\n",
      "TP: 536\tFN: 182\n",
      "FP: 223\tTN: 365\n",
      "\tTrain Loss: 0.527 | Train Acc: 73.15%\n",
      "\t Val. Loss: 0.590 |  Val. Acc: 68.99%\n",
      "precision:  0.7061923583662714\n",
      "recall:  0.7465181058495822\n",
      "f1 = 0.7257955314827353\n",
      "Epoch: 325\n",
      "TP: 534\tFN: 184\n",
      "FP: 219\tTN: 369\n",
      "\tTrain Loss: 0.523 | Train Acc: 73.50%\n",
      "\t Val. Loss: 0.595 |  Val. Acc: 69.14%\n",
      "precision:  0.7091633466135459\n",
      "recall:  0.7437325905292479\n",
      "f1 = 0.726036709721278\n",
      "Epoch: 350\n",
      "TP: 541\tFN: 177\n",
      "FP: 232\tTN: 356\n",
      "\tTrain Loss: 0.518 | Train Acc: 73.73%\n",
      "\t Val. Loss: 0.602 |  Val. Acc: 68.68%\n",
      "precision:  0.6998706338939198\n",
      "recall:  0.7534818941504178\n",
      "f1 = 0.7256874580818242\n",
      "Epoch: 375\n",
      "TP: 538\tFN: 180\n",
      "FP: 228\tTN: 360\n",
      "\tTrain Loss: 0.514 | Train Acc: 73.94%\n",
      "\t Val. Loss: 0.608 |  Val. Acc: 68.76%\n",
      "precision:  0.7023498694516971\n",
      "recall:  0.7493036211699164\n",
      "f1 = 0.725067385444744\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 400\n",
    "ep_log_interval = 25\n",
    "lrn_rate = 0.001\n",
    "sentence_dim = 32\n",
    "skill_dim = 9\n",
    "dropout = 0.1\n",
    "\n",
    "net = BertModel(sentence_dim, skill_dim, dropout)\n",
    "criterion = nn.BCEWithLogitsLoss() #BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "train_ds = create_tensors(train_data)\n",
    "test_ds = create_tensors(test_data)\n",
    "\n",
    "f1_max = [0,0]\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss, train_acc = train(net,train_ds,optimizer,criterion)\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        valid_loss, valid_acc, prec, rec = evaluate(net,test_ds,criterion,matrix=True)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print('precision: ', prec)\n",
    "        print('recall: ', rec)\n",
    "        try:\n",
    "            f1 = 2*(prec*rec)/(prec+rec)\n",
    "            print(f\"f1 = {f1}\")\n",
    "            if f1 > f1_max[0]:\n",
    "                f1_max[0] = f1\n",
    "                f1_max[1] = epoch\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7427413909520595, 225]\n"
     ]
    }
   ],
   "source": [
    "print(f1_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['G3.PPVT.Vocab.raw',\n",
    "                 'G3.Elision.PA.raw',\n",
    "                 'G3.Syn.GramCorrect.raw',\n",
    "                 'G3.TOWRE.SWE.raw',\n",
    "                 'G3.TOWRE.PDE.raw',\n",
    "                 'G3.WordID.raw',\n",
    "                 'G3.OL.Spell.Total',\n",
    "                 'G3.OL.OrthoChoice.1.2.Total',\n",
    "                 'G3.DigitSpan.raw',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN model without text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(model, data, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(data['skills']).squeeze(1)\n",
    "\n",
    "    loss = criterion(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    acc = binary_accuracy(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "#     epoch_loss += loss.item()\n",
    "#     epoch_acc += acc.item()\n",
    "#     print(loss)\n",
    "#     print(acc)\n",
    "    return loss,acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_simple(model, data, criterion, matrix=False):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(data['skills']).squeeze(1)\n",
    "        \n",
    "#         print('eval pred',predictions)\n",
    "\n",
    "        loss = criterion(predictions, data['y'])\n",
    "#         print('eval1',data[4])\n",
    "#         print('eval',(data[4]==0).sum())\n",
    "        acc = binary_accuracy(predictions, data['y'])\n",
    "        \n",
    "        prec = precision(predictions, data['y'])\n",
    "        \n",
    "        rec = recall(predictions, data['y'])\n",
    "        \n",
    "        confusion_matrix(predictions, data['y'])\n",
    "        \n",
    "#         print(f\"Number of positives: {(data[4]==1).sum()}\")\n",
    "#         print(f\"Number of negatives: {(data[4]==0).sum()}\")\n",
    "\n",
    "        \n",
    "    return loss, acc, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5222x13 and 10x20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7327a47fa152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mep_log_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-709688c94735>\u001b[0m in \u001b[0;36mtrain_simple\u001b[0;34m(model, data, optimizer, criterion)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skills'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-974cb592b126>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, skills)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_skill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskills\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5222x13 and 10x20)"
     ]
    }
   ],
   "source": [
    "max_epochs = 400\n",
    "ep_log_interval = 25\n",
    "lrn_rate = 0.001\n",
    "sentence_dim = 128\n",
    "skill_dim = 10\n",
    "dropout = 0.1\n",
    "\n",
    "net = SimpleNet(skill_dim)\n",
    "criterion = nn.BCEWithLogitsLoss() #BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "train_ds = create_tensors(train_data)\n",
    "test_ds = create_tensors(test_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss, train_acc = train_simple(net,train_ds,optimizer,criterion)\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        valid_loss, valid_acc, prec, rec = evaluate_simple(net,test_ds,criterion,matrix=True)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print('precision: ', prec)\n",
    "        print('recall: ', rec)\n",
    "        try:\n",
    "            print(f\"f1 = {2*(prec*rec)/(prec+rec)}\")\n",
    "        except:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
