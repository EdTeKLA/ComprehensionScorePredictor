{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.         26.          5.         60.         22.         59.\n",
      "  8.         21.         11.          7.66666667  1.3662601   7.\n",
      "  4.        ]\n",
      "6528\n",
      "5222\n",
      "1306\n",
      "13\n",
      "[23.         15.          2.         57.         17.         50.\n",
      "  1.         12.         11.          8.75        3.19597962  8.\n",
      "  6.        ]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.pkl\",'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "print(data[0][0])\n",
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "print(len(data))\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(data[0][0]))\n",
    "print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensors(data_list):\n",
    "    # create tensor that is compatible to load and train in the language model\n",
    "    ds = {}\n",
    "    keys = ['skills','subtests','questions','answers','y']\n",
    "    for key in keys:\n",
    "        ds[key] = []\n",
    "    \n",
    "    for entry in data_list:\n",
    "        ds['skills'].append(entry[0])\n",
    "        ds['subtests'].append(entry[1])\n",
    "        ds['questions'].append(entry[2])\n",
    "        ds['answers'].append(entry[3])\n",
    "        ds['y'].append(entry[4])\n",
    "    \n",
    "    ds['skills'] = torch.tensor(ds['skills']).type(torch.float)\n",
    "    ds['subtests'] = torch.tensor(ds['subtests'])\n",
    "    ds['questions'] = torch.tensor(ds['questions'])\n",
    "    ds['answers'] = torch.tensor(ds['answers'])\n",
    "    ds['y'] = torch.tensor(ds['y']).type(torch.float)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self, sentence_dim, skill_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.skill_dim = skill_dim\n",
    "        self.fc_test = nn.Linear(768,sentence_dim)\n",
    "        self.fc_question = nn.Linear(768,sentence_dim)\n",
    "        self.fc_answer = nn.Linear(768,sentence_dim)\n",
    "        self.fc_skill = nn.Linear(skill_dim,skill_dim*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(3*sentence_dim+skill_dim*2,128)\n",
    "        self.out = nn.Linear(128,1)\n",
    "    \n",
    "    def forward(self, skills,test,question,answer):\n",
    "        x1 = self.fc_skill(skills[:,:skill_dim])\n",
    "        x2 = self.fc_test(test)\n",
    "        x3 = self.fc_question(question)\n",
    "        x4 = self.fc_answer(answer)\n",
    "        x = torch.cat((x1,x2,x3,x4),dim=1)\n",
    "        x = self.fc2(self.relu(x))\n",
    "        pred = self.out(self.relu(x))\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, skill_dim):\n",
    "        super().__init__()\n",
    "        self.fc_skill = nn.Linear(skill_dim,skill_dim*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(skill_dim*2,128)\n",
    "        self.out = nn.Linear(128,1)\n",
    "        \n",
    "    def forward(self, skills):\n",
    "        x1 = self.fc_skill(skills)\n",
    "        x = self.fc2(self.relu(x1))\n",
    "        pred = self.out(self.relu(x))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(preds, Y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i, value in enumerate(rounded_preds):\n",
    "        if value == Y[i] and value == 1:\n",
    "            TP += 1\n",
    "        elif value == Y[i] and value == 0:\n",
    "            TN += 1\n",
    "        elif value != Y[i] and value == 0:\n",
    "            FN += 1\n",
    "        elif value != Y[i] and value == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            print(value,Y[i])\n",
    "    print(f'TP: {TP}\\tFN: {FN}')\n",
    "    print(f'FP: {FP}\\tTN: {TN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision(preds,y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "#     print((rounded_preds==1).sum())\n",
    "#     print((y==1).sum())\n",
    "    return precision_score(y,rounded_preds)\n",
    "\n",
    "def recall(preds,y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "    return recall_score(y,rounded_preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(data['skills'],data['subtests'],data['questions'],data['answers']).squeeze(1)\n",
    "\n",
    "    loss = criterion(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    acc = binary_accuracy(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "#     epoch_loss += loss.item()\n",
    "#     epoch_acc += acc.item()\n",
    "#     print(loss)\n",
    "#     print(acc)\n",
    "    return loss,acc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion, matrix=False):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(data['skills'],data['subtests'],data['questions'],data['answers']).squeeze(1)\n",
    "        \n",
    "#         print('eval pred',predictions)\n",
    "\n",
    "        loss = criterion(predictions, data['y'])\n",
    "#         print('eval1',data[4])\n",
    "#         print('eval',(data[4]==0).sum())\n",
    "        acc = binary_accuracy(predictions, data['y'])\n",
    "        \n",
    "        prec = precision(predictions, data['y'])\n",
    "        \n",
    "        rec = recall(predictions, data['y'])\n",
    "        \n",
    "        confusion_matrix(predictions, data['y'])\n",
    "        \n",
    "#         print(f\"Number of positives: {(data[4]==1).sum()}\")\n",
    "#         print(f\"Number of negatives: {(data[4]==0).sum()}\")\n",
    "\n",
    "        \n",
    "    return loss, acc, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "TP: 471\tFN: 244\n",
      "FP: 274\tTN: 317\n",
      "\tTrain Loss: 0.789 | Train Acc: 45.31%\n",
      "\t Val. Loss: 0.678 |  Val. Acc: 60.34%\n",
      "precision:  0.6322147651006711\n",
      "recall:  0.6587412587412588\n",
      "f1 = 0.6452054794520549\n",
      "Epoch: 25\n",
      "TP: 579\tFN: 136\n",
      "FP: 306\tTN: 285\n",
      "\tTrain Loss: 0.608 | Train Acc: 67.12%\n",
      "\t Val. Loss: 0.616 |  Val. Acc: 66.16%\n",
      "precision:  0.6542372881355932\n",
      "recall:  0.8097902097902098\n",
      "f1 = 0.72375\n",
      "Epoch: 50\n",
      "TP: 541\tFN: 174\n",
      "FP: 242\tTN: 349\n",
      "\tTrain Loss: 0.580 | Train Acc: 69.92%\n",
      "\t Val. Loss: 0.592 |  Val. Acc: 68.15%\n",
      "precision:  0.6909323116219668\n",
      "recall:  0.7566433566433567\n",
      "f1 = 0.7222963951935913\n",
      "Epoch: 75\n",
      "TP: 539\tFN: 176\n",
      "FP: 228\tTN: 363\n",
      "\tTrain Loss: 0.572 | Train Acc: 70.89%\n",
      "\t Val. Loss: 0.582 |  Val. Acc: 69.07%\n",
      "precision:  0.7027379400260756\n",
      "recall:  0.7538461538461538\n",
      "f1 = 0.7273954116059379\n",
      "Epoch: 100\n",
      "TP: 538\tFN: 177\n",
      "FP: 222\tTN: 369\n",
      "\tTrain Loss: 0.567 | Train Acc: 71.22%\n",
      "\t Val. Loss: 0.577 |  Val. Acc: 69.45%\n",
      "precision:  0.7078947368421052\n",
      "recall:  0.7524475524475525\n",
      "f1 = 0.7294915254237287\n",
      "Epoch: 125\n",
      "TP: 538\tFN: 177\n",
      "FP: 215\tTN: 376\n",
      "\tTrain Loss: 0.560 | Train Acc: 71.54%\n",
      "\t Val. Loss: 0.572 |  Val. Acc: 69.98%\n",
      "precision:  0.7144754316069057\n",
      "recall:  0.7524475524475525\n",
      "f1 = 0.7329700272479565\n",
      "Epoch: 150\n",
      "TP: 541\tFN: 174\n",
      "FP: 213\tTN: 378\n",
      "\tTrain Loss: 0.551 | Train Acc: 71.58%\n",
      "\t Val. Loss: 0.568 |  Val. Acc: 70.37%\n",
      "precision:  0.7175066312997348\n",
      "recall:  0.7566433566433567\n",
      "f1 = 0.7365554799183118\n",
      "Epoch: 175\n",
      "TP: 554\tFN: 161\n",
      "FP: 217\tTN: 374\n",
      "\tTrain Loss: 0.543 | Train Acc: 72.19%\n",
      "\t Val. Loss: 0.564 |  Val. Acc: 71.06%\n",
      "precision:  0.7185473411154345\n",
      "recall:  0.7748251748251749\n",
      "f1 = 0.7456258411843877\n",
      "Epoch: 200\n",
      "TP: 549\tFN: 166\n",
      "FP: 205\tTN: 386\n",
      "\tTrain Loss: 0.536 | Train Acc: 72.44%\n",
      "\t Val. Loss: 0.562 |  Val. Acc: 71.59%\n",
      "precision:  0.7281167108753316\n",
      "recall:  0.7678321678321678\n",
      "f1 = 0.7474472430224642\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 225\n",
    "ep_log_interval = 25\n",
    "lrn_rate = 0.001\n",
    "sentence_dim = 32\n",
    "skill_dim = 13\n",
    "dropout = 0.1\n",
    "\n",
    "net = BertModel(sentence_dim, skill_dim, dropout)\n",
    "criterion = nn.BCEWithLogitsLoss() #BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "train_ds = create_tensors(train_data)\n",
    "test_ds = create_tensors(test_data)\n",
    "\n",
    "f1_max = [0,0]\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss, train_acc = train(net,train_ds,optimizer,criterion)\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        valid_loss, valid_acc, prec, rec = evaluate(net,test_ds,criterion,matrix=True)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print('precision: ', prec)\n",
    "        print('recall: ', rec)\n",
    "        try:\n",
    "            f1 = 2*(prec*rec)/(prec+rec)\n",
    "            print(f\"f1 = {f1}\")\n",
    "            if f1 > f1_max[0]:\n",
    "                f1_max[0] = f1\n",
    "                f1_max[1] = epoch\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "ig = IntegratedGradients(net)\n",
    "test_ds['skills'].requires_grad_()\n",
    "test_ds['subtests'].requires_grad_()\n",
    "test_ds['questions'].requires_grad_()\n",
    "test_ds['answers'].requires_grad_()\n",
    "\n",
    "\n",
    "attr,delta = ig.attribute((test_ds['skills'],test_ds['subtests'],test_ds['questions'],test_ds['answers'])\\\n",
    "                          ,return_convergence_delta=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09100521 -1.35675336  1.00882048 ... -0.20774259 -1.48116237\n",
      "  -0.75076864]\n",
      " [ 0.83759693 -0.34807344  0.28158192 ... -0.0823799   0.30513513\n",
      "  -0.22725153]\n",
      " [-0.12756444 -1.06079944  1.61869643 ... -0.16927518 -1.21478559\n",
      "  -1.38917139]\n",
      " ...\n",
      " [ 0.61455439 -1.02378127  1.03882422 ... -0.16039462 -0.78013361\n",
      "  -0.75481036]\n",
      " [-0.08697633 -1.5277641   1.45363305 ... -0.35638056 -1.18183722\n",
      "  -1.56512035]\n",
      " [-0.57473597 -0.64854992  1.03812929 ... -0.11281245 -0.75089058\n",
      "  -0.62315688]]\n"
     ]
    }
   ],
   "source": [
    "attr = attr[0].detach().numpy()\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Feature Importances\n",
      "G3.PPVT.Vocab.raw :  0.513\n",
      "G3.Elision.PA.raw :  -0.944\n",
      "G3.Syn.GramCorrect.raw :  1.069\n",
      "G3.TOWRE.SWE.raw :  1.085\n",
      "G3.TOWRE.PDE.raw :  0.288\n",
      "G3.WordID.raw :  2.885\n",
      "G3.OL.Spell.Total :  0.236\n",
      "G3.OL.OrthoChoice.1.2.Total :  -0.080\n",
      "G3.DigitSpan.raw :  -0.009\n",
      "text_depth_avg :  -0.707\n",
      "text_depth_stdev :  -0.232\n",
      "question_depth :  -0.855\n",
      "answer_depth :  -0.771\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# attr = attr[0].detach().numpy()\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
    "    print(title)\n",
    "    for i in range(len(feature_names)):\n",
    "        print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.bar(x_pos, importances, align='center')\n",
    "        plt.xticks(x_pos, feature_names, rotation='vertical')\n",
    "        plt.xlabel(axis_title)\n",
    "        plt.title(title)\n",
    "visualize_importances(feature_names+['text_depth_avg','text_depth_stdev','question_depth','answer_depth',], np.mean(attr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7531772575250838, 275]\n"
     ]
    }
   ],
   "source": [
    "print(f1_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "TP: 715\tFN: 0\n",
      "FP: 591\tTN: 0\n",
      "\tTrain Loss: 0.692 | Train Acc: 54.60%\n",
      "\t Val. Loss: 0.679 |  Val. Acc: 54.75%\n",
      "precision:  0.5474732006125574\n",
      "recall:  1.0\n",
      "f1 = 0.7075705096486888\n",
      "Epoch: 25\n",
      "TP: 536\tFN: 179\n",
      "FP: 247\tTN: 344\n",
      "\tTrain Loss: 0.588 | Train Acc: 69.15%\n",
      "\t Val. Loss: 0.601 |  Val. Acc: 67.38%\n",
      "precision:  0.6845466155810983\n",
      "recall:  0.7496503496503496\n",
      "f1 = 0.7156208277703604\n",
      "Epoch: 50\n",
      "TP: 541\tFN: 174\n",
      "FP: 235\tTN: 356\n",
      "\tTrain Loss: 0.577 | Train Acc: 70.28%\n",
      "\t Val. Loss: 0.588 |  Val. Acc: 68.68%\n",
      "precision:  0.6971649484536082\n",
      "recall:  0.7566433566433567\n",
      "f1 = 0.7256874580818242\n",
      "Epoch: 75\n",
      "TP: 538\tFN: 177\n",
      "FP: 228\tTN: 363\n",
      "\tTrain Loss: 0.570 | Train Acc: 70.64%\n",
      "\t Val. Loss: 0.583 |  Val. Acc: 68.99%\n",
      "precision:  0.7023498694516971\n",
      "recall:  0.7524475524475525\n",
      "f1 = 0.7265361242403782\n",
      "Epoch: 100\n",
      "TP: 536\tFN: 179\n",
      "FP: 222\tTN: 369\n",
      "\tTrain Loss: 0.563 | Train Acc: 70.97%\n",
      "\t Val. Loss: 0.579 |  Val. Acc: 69.30%\n",
      "precision:  0.7071240105540897\n",
      "recall:  0.7496503496503496\n",
      "f1 = 0.7277664630006788\n",
      "Epoch: 125\n",
      "TP: 537\tFN: 178\n",
      "FP: 209\tTN: 382\n",
      "\tTrain Loss: 0.554 | Train Acc: 71.43%\n",
      "\t Val. Loss: 0.576 |  Val. Acc: 70.37%\n",
      "precision:  0.7198391420911529\n",
      "recall:  0.7510489510489511\n",
      "f1 = 0.7351129363449692\n",
      "Epoch: 150\n",
      "TP: 538\tFN: 177\n",
      "FP: 207\tTN: 384\n",
      "\tTrain Loss: 0.547 | Train Acc: 71.68%\n",
      "\t Val. Loss: 0.574 |  Val. Acc: 70.60%\n",
      "precision:  0.7221476510067114\n",
      "recall:  0.7524475524475525\n",
      "f1 = 0.736986301369863\n",
      "Epoch: 175\n",
      "TP: 529\tFN: 186\n",
      "FP: 204\tTN: 387\n",
      "\tTrain Loss: 0.541 | Train Acc: 71.98%\n",
      "\t Val. Loss: 0.573 |  Val. Acc: 70.14%\n",
      "precision:  0.7216916780354706\n",
      "recall:  0.7398601398601399\n",
      "f1 = 0.7306629834254145\n",
      "Epoch: 200\n",
      "TP: 536\tFN: 179\n",
      "FP: 206\tTN: 385\n",
      "\tTrain Loss: 0.534 | Train Acc: 72.33%\n",
      "\t Val. Loss: 0.573 |  Val. Acc: 70.52%\n",
      "precision:  0.7223719676549866\n",
      "recall:  0.7496503496503496\n",
      "f1 = 0.735758407687028\n",
      "Epoch: 225\n",
      "TP: 550\tFN: 165\n",
      "FP: 216\tTN: 375\n",
      "\tTrain Loss: 0.528 | Train Acc: 72.90%\n",
      "\t Val. Loss: 0.574 |  Val. Acc: 70.83%\n",
      "precision:  0.7180156657963447\n",
      "recall:  0.7692307692307693\n",
      "f1 = 0.7427413909520595\n",
      "Epoch: 250\n",
      "TP: 519\tFN: 196\n",
      "FP: 194\tTN: 397\n",
      "\tTrain Loss: 0.522 | Train Acc: 73.73%\n",
      "\t Val. Loss: 0.577 |  Val. Acc: 70.14%\n",
      "precision:  0.7279102384291725\n",
      "recall:  0.7258741258741259\n",
      "f1 = 0.726890756302521\n",
      "Epoch: 275\n",
      "TP: 529\tFN: 186\n",
      "FP: 206\tTN: 385\n",
      "\tTrain Loss: 0.516 | Train Acc: 73.99%\n",
      "\t Val. Loss: 0.581 |  Val. Acc: 69.98%\n",
      "precision:  0.7197278911564626\n",
      "recall:  0.7398601398601399\n",
      "f1 = 0.7296551724137931\n",
      "Epoch: 300\n",
      "TP: 529\tFN: 186\n",
      "FP: 210\tTN: 381\n",
      "\tTrain Loss: 0.510 | Train Acc: 74.38%\n",
      "\t Val. Loss: 0.586 |  Val. Acc: 69.68%\n",
      "precision:  0.7158322056833559\n",
      "recall:  0.7398601398601399\n",
      "f1 = 0.7276478679504815\n",
      "Epoch: 325\n",
      "TP: 521\tFN: 194\n",
      "FP: 201\tTN: 390\n",
      "\tTrain Loss: 0.506 | Train Acc: 74.88%\n",
      "\t Val. Loss: 0.591 |  Val. Acc: 69.75%\n",
      "precision:  0.721606648199446\n",
      "recall:  0.7286713286713287\n",
      "f1 = 0.7251217814892136\n",
      "Epoch: 350\n",
      "TP: 536\tFN: 179\n",
      "FP: 219\tTN: 372\n",
      "\tTrain Loss: 0.499 | Train Acc: 75.32%\n",
      "\t Val. Loss: 0.599 |  Val. Acc: 69.53%\n",
      "precision:  0.7099337748344371\n",
      "recall:  0.7496503496503496\n",
      "f1 = 0.729251700680272\n",
      "Epoch: 375\n",
      "TP: 537\tFN: 178\n",
      "FP: 224\tTN: 367\n",
      "\tTrain Loss: 0.493 | Train Acc: 75.78%\n",
      "\t Val. Loss: 0.606 |  Val. Acc: 69.22%\n",
      "precision:  0.7056504599211564\n",
      "recall:  0.7510489510489511\n",
      "f1 = 0.7276422764227642\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 400\n",
    "ep_log_interval = 25\n",
    "lrn_rate = 0.001\n",
    "sentence_dim = 32\n",
    "skill_dim = 9\n",
    "dropout = 0.1\n",
    "\n",
    "net = BertModel(sentence_dim, skill_dim, dropout)\n",
    "criterion = nn.BCEWithLogitsLoss() #BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "train_ds = create_tensors(train_data)\n",
    "test_ds = create_tensors(test_data)\n",
    "\n",
    "f1_max = [0,0]\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss, train_acc = train(net,train_ds,optimizer,criterion)\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        valid_loss, valid_acc, prec, rec = evaluate(net,test_ds,criterion,matrix=True)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print('precision: ', prec)\n",
    "        print('recall: ', rec)\n",
    "        try:\n",
    "            f1 = 2*(prec*rec)/(prec+rec)\n",
    "            print(f\"f1 = {f1}\")\n",
    "            if f1 > f1_max[0]:\n",
    "                f1_max[0] = f1\n",
    "                f1_max[1] = epoch\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7427413909520595, 225]\n"
     ]
    }
   ],
   "source": [
    "print(f1_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['G3.PPVT.Vocab.raw',\n",
    "                 'G3.Elision.PA.raw',\n",
    "                 'G3.Syn.GramCorrect.raw',\n",
    "                 'G3.TOWRE.SWE.raw',\n",
    "                 'G3.TOWRE.PDE.raw',\n",
    "                 'G3.WordID.raw',\n",
    "                 'G3.OL.Spell.Total',\n",
    "                 'G3.OL.OrthoChoice.1.2.Total',\n",
    "                 'G3.DigitSpan.raw',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "min() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * ()\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-351f7cffe9ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_tabular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_tabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLimeTabularExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skills'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lime/lime_tabular.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiscretizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quartile'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 self.discretizer = QuartileDiscretizer(\n\u001b[0m\u001b[1;32m    216\u001b[0m                         \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lime/discretize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         BaseDiscretizer.__init__(self, data, categorical_features,\n\u001b[0m\u001b[1;32m    179\u001b[0m                                  \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                                  random_state=random_state)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lime/discretize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state, data_stats)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_discretize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mn_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Actually number of borders (= #bins-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mboundaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2856\u001b[0m     \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m     \"\"\"\n\u001b[0;32m-> 2858\u001b[0;31m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0m\u001b[1;32m   2859\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: min() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * ()\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(train_ds['skills'], mode=\"regression\", feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN model without text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(model, data, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(data['skills']).squeeze(1)\n",
    "\n",
    "    loss = criterion(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    acc = binary_accuracy(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "#     epoch_loss += loss.item()\n",
    "#     epoch_acc += acc.item()\n",
    "#     print(loss)\n",
    "#     print(acc)\n",
    "    return loss,acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_simple(model, data, criterion, matrix=False):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(data['skills']).squeeze(1)\n",
    "        \n",
    "#         print('eval pred',predictions)\n",
    "\n",
    "        loss = criterion(predictions, data['y'])\n",
    "#         print('eval1',data[4])\n",
    "#         print('eval',(data[4]==0).sum())\n",
    "        acc = binary_accuracy(predictions, data['y'])\n",
    "        \n",
    "        prec = precision(predictions, data['y'])\n",
    "        \n",
    "        rec = recall(predictions, data['y'])\n",
    "        \n",
    "        confusion_matrix(predictions, data['y'])\n",
    "        \n",
    "#         print(f\"Number of positives: {(data[4]==1).sum()}\")\n",
    "#         print(f\"Number of negatives: {(data[4]==0).sum()}\")\n",
    "\n",
    "        \n",
    "    return loss, acc, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "TP: 8\tFN: 730\n",
      "FP: 21\tTN: 547\n",
      "\tTrain Loss: 1.093 | Train Acc: 45.40%\n",
      "\t Val. Loss: 0.839 |  Val. Acc: 42.50%\n",
      "precision:  0.27586206896551724\n",
      "recall:  0.01084010840108401\n",
      "f1 = 0.020860495436766623\n",
      "Epoch: 25\n",
      "TP: 620\tFN: 118\n",
      "FP: 324\tTN: 244\n",
      "\tTrain Loss: 0.649 | Train Acc: 61.05%\n",
      "\t Val. Loss: 0.625 |  Val. Acc: 66.16%\n",
      "precision:  0.6567796610169492\n",
      "recall:  0.8401084010840109\n",
      "f1 = 0.7372175980975029\n",
      "Epoch: 50\n",
      "TP: 593\tFN: 145\n",
      "FP: 277\tTN: 291\n",
      "\tTrain Loss: 0.634 | Train Acc: 64.29%\n",
      "\t Val. Loss: 0.611 |  Val. Acc: 67.69%\n",
      "precision:  0.6816091954022988\n",
      "recall:  0.8035230352303523\n",
      "f1 = 0.7375621890547263\n",
      "Epoch: 75\n",
      "TP: 555\tFN: 183\n",
      "FP: 237\tTN: 331\n",
      "\tTrain Loss: 0.625 | Train Acc: 65.47%\n",
      "\t Val. Loss: 0.609 |  Val. Acc: 67.84%\n",
      "precision:  0.7007575757575758\n",
      "recall:  0.7520325203252033\n",
      "f1 = 0.7254901960784315\n",
      "Epoch: 100\n",
      "TP: 568\tFN: 170\n",
      "FP: 242\tTN: 326\n",
      "\tTrain Loss: 0.616 | Train Acc: 66.60%\n",
      "\t Val. Loss: 0.602 |  Val. Acc: 68.45%\n",
      "precision:  0.7012345679012346\n",
      "recall:  0.7696476964769647\n",
      "f1 = 0.7338501291989664\n",
      "Epoch: 125\n",
      "TP: 570\tFN: 168\n",
      "FP: 235\tTN: 333\n",
      "\tTrain Loss: 0.611 | Train Acc: 67.16%\n",
      "\t Val. Loss: 0.595 |  Val. Acc: 69.14%\n",
      "precision:  0.7080745341614907\n",
      "recall:  0.7723577235772358\n",
      "f1 = 0.7388204795852236\n",
      "Epoch: 150\n",
      "TP: 571\tFN: 167\n",
      "FP: 232\tTN: 336\n",
      "\tTrain Loss: 0.608 | Train Acc: 67.71%\n",
      "\t Val. Loss: 0.594 |  Val. Acc: 69.45%\n",
      "precision:  0.7110834371108343\n",
      "recall:  0.7737127371273713\n",
      "f1 = 0.7410772225827386\n",
      "Epoch: 175\n",
      "TP: 570\tFN: 168\n",
      "FP: 231\tTN: 337\n",
      "\tTrain Loss: 0.606 | Train Acc: 67.66%\n",
      "\t Val. Loss: 0.593 |  Val. Acc: 69.45%\n",
      "precision:  0.7116104868913857\n",
      "recall:  0.7723577235772358\n",
      "f1 = 0.7407407407407406\n",
      "Epoch: 200\n",
      "TP: 573\tFN: 165\n",
      "FP: 233\tTN: 335\n",
      "\tTrain Loss: 0.605 | Train Acc: 67.56%\n",
      "\t Val. Loss: 0.592 |  Val. Acc: 69.53%\n",
      "precision:  0.7109181141439206\n",
      "recall:  0.7764227642276422\n",
      "f1 = 0.7422279792746114\n",
      "Epoch: 225\n",
      "TP: 572\tFN: 166\n",
      "FP: 227\tTN: 341\n",
      "\tTrain Loss: 0.604 | Train Acc: 67.46%\n",
      "\t Val. Loss: 0.592 |  Val. Acc: 69.91%\n",
      "precision:  0.7158948685857321\n",
      "recall:  0.7750677506775068\n",
      "f1 = 0.7443070917371503\n",
      "Epoch: 250\n",
      "TP: 577\tFN: 161\n",
      "FP: 227\tTN: 341\n",
      "\tTrain Loss: 0.603 | Train Acc: 67.60%\n",
      "\t Val. Loss: 0.591 |  Val. Acc: 70.29%\n",
      "precision:  0.7176616915422885\n",
      "recall:  0.7818428184281843\n",
      "f1 = 0.7483787289234759\n",
      "Epoch: 275\n",
      "TP: 577\tFN: 161\n",
      "FP: 226\tTN: 342\n",
      "\tTrain Loss: 0.602 | Train Acc: 67.60%\n",
      "\t Val. Loss: 0.591 |  Val. Acc: 70.37%\n",
      "precision:  0.7185554171855542\n",
      "recall:  0.7818428184281843\n",
      "f1 = 0.7488643737832575\n",
      "Epoch: 300\n",
      "TP: 577\tFN: 161\n",
      "FP: 226\tTN: 342\n",
      "\tTrain Loss: 0.601 | Train Acc: 67.81%\n",
      "\t Val. Loss: 0.590 |  Val. Acc: 70.37%\n",
      "precision:  0.7185554171855542\n",
      "recall:  0.7818428184281843\n",
      "f1 = 0.7488643737832575\n",
      "Epoch: 325\n",
      "TP: 577\tFN: 161\n",
      "FP: 226\tTN: 342\n",
      "\tTrain Loss: 0.600 | Train Acc: 68.00%\n",
      "\t Val. Loss: 0.590 |  Val. Acc: 70.37%\n",
      "precision:  0.7185554171855542\n",
      "recall:  0.7818428184281843\n",
      "f1 = 0.7488643737832575\n",
      "Epoch: 350\n",
      "TP: 577\tFN: 161\n",
      "FP: 226\tTN: 342\n",
      "\tTrain Loss: 0.599 | Train Acc: 68.08%\n",
      "\t Val. Loss: 0.589 |  Val. Acc: 70.37%\n",
      "precision:  0.7185554171855542\n",
      "recall:  0.7818428184281843\n",
      "f1 = 0.7488643737832575\n",
      "Epoch: 375\n",
      "TP: 579\tFN: 159\n",
      "FP: 228\tTN: 340\n",
      "\tTrain Loss: 0.598 | Train Acc: 67.83%\n",
      "\t Val. Loss: 0.589 |  Val. Acc: 70.37%\n",
      "precision:  0.7174721189591078\n",
      "recall:  0.7845528455284553\n",
      "f1 = 0.7495145631067961\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 400\n",
    "ep_log_interval = 25\n",
    "lrn_rate = 0.001\n",
    "sentence_dim = 128\n",
    "skill_dim = 10\n",
    "dropout = 0.1\n",
    "\n",
    "net = SimpleNet(skill_dim)\n",
    "criterion = nn.BCEWithLogitsLoss() #BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "train_ds = create_tensors(train_data)\n",
    "test_ds = create_tensors(test_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss, train_acc = train_simple(net,train_ds,optimizer,criterion)\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        valid_loss, valid_acc, prec, rec = evaluate_simple(net,test_ds,criterion,matrix=True)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print('precision: ', prec)\n",
    "        print('recall: ', rec)\n",
    "        try:\n",
    "            print(f\"f1 = {2*(prec*rec)/(prec+rec)}\")\n",
    "        except:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
