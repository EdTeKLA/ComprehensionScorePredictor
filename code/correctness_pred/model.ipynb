{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5808\n",
      "4646\n",
      "1162\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.pkl\",'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "random.shuffle(data)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "print(len(data))\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensors(data_list):\n",
    "    # create tensor that is compatible to load and train in the language model\n",
    "    ds = {}\n",
    "    keys = ['skills','subtests','questions','answers','y']\n",
    "    for key in keys:\n",
    "        ds[key] = []\n",
    "    \n",
    "    for entry in data_list:\n",
    "        ds['skills'].append(entry[0])\n",
    "        ds['subtests'].append(entry[1])\n",
    "        ds['questions'].append(entry[2])\n",
    "        ds['answers'].append(entry[3])\n",
    "        ds['y'].append(entry[4])\n",
    "    \n",
    "    ds['skills'] = torch.tensor(ds['skills']).type(torch.float)\n",
    "    ds['subtests'] = torch.tensor(ds['subtests'])\n",
    "    ds['questions'] = torch.tensor(ds['questions'])\n",
    "    ds['answers'] = torch.tensor(ds['answers'])\n",
    "    ds['y'] = torch.tensor(ds['y']).type(torch.float)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills = []\n",
    "# subtests = []\n",
    "# questions = []\n",
    "# answers = []\n",
    "# y = []\n",
    "# for entry in data:\n",
    "#     skills.append(entry[0])\n",
    "#     subtests.append(entry[1])\n",
    "#     questions.append(entry[2])\n",
    "#     answers.append(entry[3])\n",
    "#     y.append(entry[4])\n",
    "\n",
    "# skills = torch.tensor(skills).type(torch.float)\n",
    "# subtests = torch.tensor(subtests)\n",
    "# questions = torch.tensor(questions)\n",
    "# answers = torch.tensor(answers)\n",
    "# y = torch.tensor(y).type(torch.float)\n",
    "# # print((y[4000:]==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self, sentence_dim, skill_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc_test = nn.Linear(768,sentence_dim)\n",
    "        self.fc_question = nn.Linear(768,sentence_dim)\n",
    "        self.fc_answer = nn.Linear(768,sentence_dim)\n",
    "        self.fc_skill = nn.Linear(skill_dim,skill_dim*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(3*sentence_dim+skill_dim*2,128)\n",
    "        self.out = nn.Linear(128,1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, skills,test,question,answer):\n",
    "        x1 = self.fc_skill(skills)\n",
    "        x2 = self.fc_test(test)\n",
    "        x3 = self.fc_question(question)\n",
    "        x4 = self.fc_answer(answer)\n",
    "        x = torch.cat((x1,x2,x3,x4),dim=1)\n",
    "        x = self.fc2(self.relu(x))\n",
    "        pred = self.out(x)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(preds, Y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i, value in enumerate(rounded_preds):\n",
    "        if value == Y[i] and value == 1:\n",
    "            TP += 1\n",
    "        elif value == Y[i] and value == 0:\n",
    "            TN += 1\n",
    "        elif value != Y[i] and value == 0:\n",
    "            FN += 1\n",
    "        elif value != Y[i] and value == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            print(value,Y[i])\n",
    "    print(f'TP: {TP}\\tFN: {FN}')\n",
    "    print(f'FP: {FP}\\tTN: {TN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision(preds,y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "#     print((rounded_preds==1).sum())\n",
    "#     print((y==1).sum())\n",
    "    return precision_score(y,rounded_preds)\n",
    "\n",
    "def recall(preds,y):\n",
    "    rounded_preds = torch.round(preds.sigmoid())\n",
    "    return recall_score(y,rounded_preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(data['skills'],data['subtests'],data['questions'],data['answers']).squeeze(1)\n",
    "\n",
    "    loss = criterion(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    acc = binary_accuracy(predictions, data['y'])\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "#     epoch_loss += loss.item()\n",
    "#     epoch_acc += acc.item()\n",
    "#     print(loss)\n",
    "#     print(acc)\n",
    "    return loss,acc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion, matrix=False):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(data['skills'],data['subtests'],data['questions'],data['answers']).squeeze(1)\n",
    "        \n",
    "#         print('eval pred',predictions)\n",
    "\n",
    "        loss = criterion(predictions, data['y'])\n",
    "#         print('eval1',data[4])\n",
    "#         print('eval',(data[4]==0).sum())\n",
    "        acc = binary_accuracy(predictions, data['y'])\n",
    "        \n",
    "        prec = precision(predictions, data['y'])\n",
    "        \n",
    "        rec = recall(predictions, data['y'])\n",
    "        \n",
    "        confusion_matrix(predictions, data['y'])\n",
    "        \n",
    "#         print(f\"Number of positives: {(data[4]==1).sum()}\")\n",
    "#         print(f\"Number of negatives: {(data[4]==0).sum()}\")\n",
    "\n",
    "        \n",
    "    return loss, acc, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bnie/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-13-ee1508ce8f5a>:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"f1 = {2*(prec*rec)/(prec+rec)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0\tFN: 672\n",
      "FP: 0\tTN: 490\n",
      "\tTrain Loss: 0.671 | Train Acc: 57.04%\n",
      "\t Val. Loss: 1.810 |  Val. Acc: 42.17%\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1 = nan\n",
      "TP: 573\tFN: 99\n",
      "FP: 276\tTN: 214\n",
      "\tTrain Loss: 0.632 | Train Acc: 65.02%\n",
      "\t Val. Loss: 0.623 |  Val. Acc: 67.73%\n",
      "precision:  0.6749116607773852\n",
      "recall:  0.8526785714285714\n",
      "f1 = 0.7534516765285996\n",
      "TP: 541\tFN: 131\n",
      "FP: 250\tTN: 240\n",
      "\tTrain Loss: 0.599 | Train Acc: 68.02%\n",
      "\t Val. Loss: 0.607 |  Val. Acc: 67.21%\n",
      "precision:  0.683944374209861\n",
      "recall:  0.8050595238095238\n",
      "f1 = 0.7395762132604239\n",
      "TP: 517\tFN: 155\n",
      "FP: 202\tTN: 288\n",
      "\tTrain Loss: 0.588 | Train Acc: 69.29%\n",
      "\t Val. Loss: 0.598 |  Val. Acc: 69.28%\n",
      "precision:  0.7190542420027817\n",
      "recall:  0.7693452380952381\n",
      "f1 = 0.7433501078360892\n",
      "TP: 533\tFN: 139\n",
      "FP: 208\tTN: 282\n",
      "\tTrain Loss: 0.580 | Train Acc: 69.48%\n",
      "\t Val. Loss: 0.590 |  Val. Acc: 70.14%\n",
      "precision:  0.7192982456140351\n",
      "recall:  0.7931547619047619\n",
      "f1 = 0.754423213021939\n",
      "TP: 531\tFN: 141\n",
      "FP: 206\tTN: 284\n",
      "\tTrain Loss: 0.576 | Train Acc: 69.72%\n",
      "\t Val. Loss: 0.586 |  Val. Acc: 70.14%\n",
      "precision:  0.7204884667571235\n",
      "recall:  0.7901785714285714\n",
      "f1 = 0.7537260468417318\n",
      "TP: 530\tFN: 142\n",
      "FP: 195\tTN: 295\n",
      "\tTrain Loss: 0.573 | Train Acc: 70.08%\n",
      "\t Val. Loss: 0.584 |  Val. Acc: 71.00%\n",
      "precision:  0.7310344827586207\n",
      "recall:  0.7886904761904762\n",
      "f1 = 0.7587687902648532\n",
      "TP: 531\tFN: 141\n",
      "FP: 190\tTN: 300\n",
      "\tTrain Loss: 0.572 | Train Acc: 70.40%\n",
      "\t Val. Loss: 0.583 |  Val. Acc: 71.51%\n",
      "precision:  0.7364771151178918\n",
      "recall:  0.7901785714285714\n",
      "f1 = 0.7623833452979182\n",
      "TP: 532\tFN: 140\n",
      "FP: 189\tTN: 301\n",
      "\tTrain Loss: 0.571 | Train Acc: 70.62%\n",
      "\t Val. Loss: 0.582 |  Val. Acc: 71.69%\n",
      "precision:  0.7378640776699029\n",
      "recall:  0.7916666666666666\n",
      "f1 = 0.7638190954773869\n",
      "TP: 531\tFN: 141\n",
      "FP: 191\tTN: 299\n",
      "\tTrain Loss: 0.570 | Train Acc: 70.75%\n",
      "\t Val. Loss: 0.581 |  Val. Acc: 71.43%\n",
      "precision:  0.7354570637119113\n",
      "recall:  0.7901785714285714\n",
      "f1 = 0.7618364418938306\n",
      "TP: 535\tFN: 137\n",
      "FP: 192\tTN: 298\n",
      "\tTrain Loss: 0.569 | Train Acc: 70.75%\n",
      "\t Val. Loss: 0.580 |  Val. Acc: 71.69%\n",
      "precision:  0.7359009628610729\n",
      "recall:  0.7961309523809523\n",
      "f1 = 0.7648320228734811\n",
      "TP: 534\tFN: 138\n",
      "FP: 192\tTN: 298\n",
      "\tTrain Loss: 0.569 | Train Acc: 70.73%\n",
      "\t Val. Loss: 0.580 |  Val. Acc: 71.60%\n",
      "precision:  0.7355371900826446\n",
      "recall:  0.7946428571428571\n",
      "f1 = 0.7639484978540771\n",
      "TP: 533\tFN: 139\n",
      "FP: 190\tTN: 300\n",
      "\tTrain Loss: 0.569 | Train Acc: 70.88%\n",
      "\t Val. Loss: 0.580 |  Val. Acc: 71.69%\n",
      "precision:  0.7372060857538036\n",
      "recall:  0.7931547619047619\n",
      "f1 = 0.76415770609319\n",
      "TP: 532\tFN: 140\n",
      "FP: 190\tTN: 300\n",
      "\tTrain Loss: 0.568 | Train Acc: 71.03%\n",
      "\t Val. Loss: 0.579 |  Val. Acc: 71.60%\n",
      "precision:  0.7368421052631579\n",
      "recall:  0.7916666666666666\n",
      "f1 = 0.7632711621233859\n",
      "TP: 533\tFN: 139\n",
      "FP: 187\tTN: 303\n",
      "\tTrain Loss: 0.568 | Train Acc: 71.07%\n",
      "\t Val. Loss: 0.579 |  Val. Acc: 71.94%\n",
      "precision:  0.7402777777777778\n",
      "recall:  0.7931547619047619\n",
      "f1 = 0.7658045977011495\n",
      "TP: 544\tFN: 128\n",
      "FP: 197\tTN: 293\n",
      "\tTrain Loss: 0.568 | Train Acc: 71.18%\n",
      "\t Val. Loss: 0.578 |  Val. Acc: 72.03%\n",
      "precision:  0.7341430499325237\n",
      "recall:  0.8095238095238095\n",
      "f1 = 0.7699929228591649\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 400\n",
    "ep_log_interval = 25\n",
    "lrn_rate = 0.002\n",
    "sentence_dim = 128\n",
    "skill_dim = 9\n",
    "dropout = 0.1\n",
    "\n",
    "net = BertModel(sentence_dim, skill_dim, dropout)\n",
    "criterion = nn.BCEWithLogitsLoss() #BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "train_ds = create_tensors(train_data)\n",
    "test_ds = create_tensors(test_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss, train_acc = train(net,train_ds,optimizer,criterion)\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        valid_loss, valid_acc, prec, rec = evaluate(net,test_ds,criterion,matrix=True)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print('precision: ', prec)\n",
    "        print('recall: ', rec)\n",
    "        try:\n",
    "            print(f\"f1 = {2*(prec*rec)/(prec+rec)}\")\n",
    "        except:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
