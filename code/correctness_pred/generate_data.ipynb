{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import nltk\n",
    "from nltk.parse import CoreNLPParser\n",
    "import statistics\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = \"3\"\n",
    "target_path = f\"../../data/question_correctness/.csv\"\n",
    "scores_path = \"../../Gates.ReadComp_By-Item_Gr3-5(CM).xlsx\"\n",
    "corpus_path = f\"../../subtest_txt/gr{grade}_paragraphs.txt\"\n",
    "questions_path = f\"../../subtest_txt/gr{grade}_questions.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtest Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gr3.RC.Gates_01', 'Gr3.RC.Gates_02', 'Gr3.RC.Gates_03',\n",
      "       'Gr3.RC.Gates_04', 'Gr3.RC.Gates_05', 'Gr3.RC.Gates_06',\n",
      "       'Gr3.RC.Gates_07', 'Gr3.RC.Gates_08', 'Gr3.RC.Gates_09',\n",
      "       'Gr3.RC.Gates_10',\n",
      "       ...\n",
      "       'Gr5.RC.Gates_45', 'Gr5.RC.Gates_46', 'Gr5.RC.Gates_47',\n",
      "       'Gr5.RC.Gates_48', 'Gr5.RC.Gates_RawScore', 'Gr5.RC.Gates_GradeEquiv',\n",
      "       'Gr5.RC.Gates_NCE', 'Gr5.RC.Gates_NPR', 'Gr5.RC.Gates_NS',\n",
      "       'Gr5.RC.Gates_ESS'],\n",
      "      dtype='object', length=162)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c0b263570246b4a7617fa6418ee02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(12, 768)\n"
     ]
    }
   ],
   "source": [
    "sub_tests = []\n",
    "with open(corpus_path,'r') as fp:\n",
    "    sub_test = fp.readline()\n",
    "    while sub_test:\n",
    "        sub_tests.append(sub_test)\n",
    "        sub_test = fp.readline()\n",
    "\n",
    "\n",
    "df = pd.read_excel(scores_path)\n",
    "sub_test_number = df.columns[1:]\n",
    "\n",
    "print(sub_test_number)\n",
    "\n",
    "questions_ranges = [(1,5), (6,8), (9,13), (14,16), (17,21), (22,27), (28,30),\n",
    "                   (31,35), (36,40), (41,43), (44,48)]\n",
    "\n",
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
    "\n",
    "#Change the length to 200\n",
    "model.max_seq_length = 500\n",
    "\n",
    "sub_tests_embed = model.encode(sub_tests, show_progress_bar=True)\n",
    "\n",
    "print(sub_tests_embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate parse tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_depth(parser,text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "#     print(sentences)\n",
    "    depths = []\n",
    "    for s in sentences:\n",
    "        parse = next(parser.raw_parse(s))\n",
    "#         parse.draw()\n",
    "        depths.append(parse.height())\n",
    "        \n",
    "    return statistics.mean(depths)\n",
    "\n",
    "def get_depth_stats(parser,text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "#     print(sentences)\n",
    "    depths = []\n",
    "    for s in sentences:\n",
    "        parse = next(parser.raw_parse(s))\n",
    "#         parse.draw()\n",
    "        depths.append(parse.height())\n",
    "        \n",
    "    return [statistics.mean(depths), statistics.stdev(depths), max(depths)]\n",
    "#     return [min(depths), max(depths)]\n",
    "\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "\n",
    "# parse = next(parser.raw_parse(nltk.sent_tokenize(sub_tests[7])[4]))\n",
    "# print(parse.height())\n",
    "# parse.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions and Answers Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bb9d9e5b9e475ba7e3db86b300bdfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2f3a5e7703436f98fc104dfa581f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(48, 768)\n",
      "(48, 768)\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "with open(questions_path,'r') as fp:\n",
    "    for _ in range(48):\n",
    "        question = fp.readline()\n",
    "        answer = fp.readline()\n",
    "#         print(question,answer)\n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "        \n",
    "print(len(questions))\n",
    "print(len(answers))\n",
    "\n",
    "questions_embed = model.encode(questions, show_progress_bar=True)\n",
    "answers_embed = model.encode(answers, show_progress_bar=True)\n",
    "\n",
    "print(questions_embed.shape)\n",
    "print(answers_embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = []\n",
    "questions_depth = []\n",
    "answer_depth = []\n",
    "\n",
    "for text in sub_tests:\n",
    "    depths.append(get_depth_stats(parser,text))\n",
    "\n",
    "for q in questions:\n",
    "    questions_depth.append(get_average_depth(parser,q))\n",
    "\n",
    "for a in answers:\n",
    "    answer_depth.append(get_average_depth(parser,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = \"../../SoR_Alberta.Shared.Data.and.Codebook.xlsx\"#\"../data/gr3/gr3_features.xlsx\"\n",
    "feature_names = ['G3.PPVT.Vocab.raw',\n",
    "                 'G3.Elision.PA.raw',\n",
    "                 'G3.Syn.GramCorrect.raw',\n",
    "                 'G3.OL.Spell.Total',\n",
    "                 'G3.DigitSpan.raw',]\n",
    "combined_feature_names = [\n",
    "                 'G3.TOWRE.SWE.raw',\n",
    "                 'G3.TOWRE.PDE.raw',\n",
    "                 'G3.WordID.raw',\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble all features into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 3)\n",
      "(139,)\n",
      "[33.         26.          5.          8.         11.          1.83187109\n",
      "  7.66666667  1.3662601  10.          7.          4.        ]\n",
      "[29.         26.          7.          8.         11.          1.71471281\n",
      "  7.66666667  1.3662601  10.          7.          4.        ]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "df2 = pd.read_excel(feature_path)\n",
    "\n",
    "combined = []\n",
    "# Calculate combined feature G3.word_recog\n",
    "for i in df.index:\n",
    "    unavailable = False\n",
    "    # check if all data features are avaiable, else skip this entry\n",
    "    for col in combined_feature_names:\n",
    "        if df2[col][i] < 0:\n",
    "            unavailable = True\n",
    "            break\n",
    "\n",
    "    if unavailable:\n",
    "        continue\n",
    "    # collect all skill features\n",
    "    new_entry = []\n",
    "    for name in combined_feature_names:\n",
    "        new_entry.append(df2[name][i])\n",
    "\n",
    "    combined.append(new_entry)\n",
    "\n",
    "combined = np.asarray(combined)\n",
    "\n",
    "print(combined.shape)\n",
    "\n",
    "combined = preprocessing.normalize(combined, norm='max',axis=0)\n",
    "\n",
    "word_recog = np.sum(combined, axis = 1)\n",
    "print(word_recog.shape)\n",
    "\n",
    "for i in df.index:\n",
    "    is_available = True\n",
    "    skills = []\n",
    "    # Retrieve all skill feature data\n",
    "    for name in feature_names:\n",
    "        value = df2[name][i]\n",
    "        if value < 0:\n",
    "            is_available = False\n",
    "            break\n",
    "        skills.append(value)\n",
    "    if not is_available:\n",
    "        continue\n",
    "    # the line below will cause issue when there's missing data in entries, due to unmatched index\n",
    "    skills.append(word_recog[i])\n",
    "    \n",
    "    for index, q_range in enumerate(questions_ranges):\n",
    "        entry = []\n",
    "        entry.append(skills+depths[index])\n",
    "        entry.append(sub_tests_embed[index])\n",
    "        for j in range(q_range[0],q_range[1]+1):\n",
    "            # add embeddings\n",
    "            detail = []\n",
    "            detail.append(questions_embed[j-1])\n",
    "            detail.append(answers_embed[j-1])\n",
    "            # add cfg depth\n",
    "            new_entry = copy.deepcopy(entry)\n",
    "\n",
    "            new_entry[0] += [questions_depth[j-1],answer_depth[j-1]]\n",
    "            new_entry[0] = np.asarray(new_entry[0])\n",
    "            \n",
    "            if df[f\"Gr{grade}.RC.Gates_\"+\"{:02d}\".format(j)][i] == 1:\n",
    "                detail.append(1)\n",
    "            elif df[f\"Gr{grade}.RC.Gates_\"+\"{:02d}\".format(j)][i] in (2,0):\n",
    "                detail.append(0)\n",
    "            else:\n",
    "                print('DNE')\n",
    "            data.append(new_entry+detail)\n",
    "\n",
    "print(data[0][0])\n",
    "print(data[48][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",'wb') as fp:\n",
    "    pickle.dump(data, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",'rb') as fp:\n",
    "    new_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data[1][0]))\n",
    "# print(len(new_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
