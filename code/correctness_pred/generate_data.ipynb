{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pickle\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = \"3\"\n",
    "target_path = f\"../../data/question_correctness/.csv\"\n",
    "scores_path = \"../../Gates.ReadComp_By-Item_Gr3-5(CM).xlsx\"\n",
    "corpus_path = f\"../../subtest_txt/gr{grade}_paragraphs.txt\"\n",
    "questions_path = f\"../../subtest_txt/gr{grade}_questions.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gr3.RC.Gates_01', 'Gr3.RC.Gates_02', 'Gr3.RC.Gates_03',\n",
      "       'Gr3.RC.Gates_04', 'Gr3.RC.Gates_05', 'Gr3.RC.Gates_06',\n",
      "       'Gr3.RC.Gates_07', 'Gr3.RC.Gates_08', 'Gr3.RC.Gates_09',\n",
      "       'Gr3.RC.Gates_10',\n",
      "       ...\n",
      "       'Gr5.RC.Gates_45', 'Gr5.RC.Gates_46', 'Gr5.RC.Gates_47',\n",
      "       'Gr5.RC.Gates_48', 'Gr5.RC.Gates_RawScore', 'Gr5.RC.Gates_GradeEquiv',\n",
      "       'Gr5.RC.Gates_NCE', 'Gr5.RC.Gates_NPR', 'Gr5.RC.Gates_NS',\n",
      "       'Gr5.RC.Gates_ESS'],\n",
      "      dtype='object', length=162)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7542ae807d3944029a91cf754cd1e5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(12, 768)\n"
     ]
    }
   ],
   "source": [
    "sub_tests = []\n",
    "with open(corpus_path,'r') as fp:\n",
    "    sub_test = fp.readline()\n",
    "    while sub_test:\n",
    "        sub_tests.append(sub_test)\n",
    "        sub_test = fp.readline()\n",
    "\n",
    "\n",
    "df = pd.read_excel(scores_path)\n",
    "sub_test_number = df.columns[1:]\n",
    "\n",
    "print(sub_test_number)\n",
    "\n",
    "questions_ranges = [(1,5), (6,8), (9,13), (14,16), (17,21), (22,27), (28,30),\n",
    "                   (31,35), (36,40), (41,43), (44,48)]\n",
    "\n",
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
    "\n",
    "#Change the length to 200\n",
    "model.max_seq_length = 500\n",
    "\n",
    "sub_tests_embed = model.encode(sub_tests, show_progress_bar=True)\n",
    "\n",
    "print(sub_tests_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.parse import CoreNLPParser\n",
    "import statistics\n",
    "\n",
    "def get_average_depth(parser,text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "#     print(sentences)\n",
    "    depths = []\n",
    "    for s in sentences:\n",
    "        parse = next(parser.raw_parse(s))\n",
    "#         parse.draw()\n",
    "        depths.append(parse.height())\n",
    "        \n",
    "    return statistics.mean(depths)\n",
    "\n",
    "def get_avg_stdev_depth(parser,text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "#     print(sentences)\n",
    "    depths = []\n",
    "    for s in sentences:\n",
    "        parse = next(parser.raw_parse(s))\n",
    "#         parse.draw()\n",
    "        depths.append(parse.height())\n",
    "        \n",
    "    return [statistics.mean(depths), statistics.stdev(depths)]\n",
    "\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "\n",
    "# parse = next(parser.raw_parse(nltk.sent_tokenize(sub_tests[7])[4]))\n",
    "# print(parse.height())\n",
    "# parse.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.666666666666667, 1.3662601021279464], [9, 2.0], [8.75, 3.1959796173138706], [8, 1.3416407864998738], [7.375, 1.9226098333849673], [8.235294117647058, 2.305683514836378], [10.333333333333334, 3.9619401430321606], [8, 3.2145502536643185], [9.571428571428571, 2.14919697074224], [8.071428571428571, 2.234839031005476], [8.75, 1.9086270308410553], [7.181818181818182, 2.238970078627004]]\n"
     ]
    }
   ],
   "source": [
    "depths = []\n",
    "for text in sub_tests:\n",
    "    depths.append(get_avg_stdev_depth(parser,text))\n",
    "\n",
    "print(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5127fc4e264a4f878ddceca50d92f0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86061ac6435745d79a6071fce9af63e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(48, 768)\n",
      "(48, 768)\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "with open(questions_path,'r') as fp:\n",
    "    for _ in range(48):\n",
    "        question = fp.readline()\n",
    "        answer = fp.readline()\n",
    "#         print(question,answer)\n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "        \n",
    "print(len(questions))\n",
    "print(len(answers))\n",
    "\n",
    "questions_embed = model.encode(questions, show_progress_bar=True)\n",
    "answers_embed = model.encode(answers, show_progress_bar=True)\n",
    "\n",
    "print(questions_embed.shape)\n",
    "print(answers_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_depth = []\n",
    "answer_depth = []\n",
    "\n",
    "for q in questions:\n",
    "    questions_depth.append(get_average_depth(parser,q))\n",
    "\n",
    "for a in answers:\n",
    "    answer_depth.append(get_average_depth(parser,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = \"../../SoR_Alberta.Shared.Data.and.Codebook.xlsx\"#\"../data/gr3/gr3_features.xlsx\"\n",
    "feature_names = ['G3.PPVT.Vocab.raw',\n",
    "                 'G3.Elision.PA.raw',\n",
    "                 'G3.Syn.GramCorrect.raw',\n",
    "                 'G3.TOWRE.SWE.raw',\n",
    "                 'G3.TOWRE.PDE.raw',\n",
    "                 'G3.WordID.raw',\n",
    "                 'G3.OL.Spell.Total',\n",
    "                 'G3.OL.OrthoChoice.1.2.Total',\n",
    "                 'G3.DigitSpan.raw',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.         26.          5.         60.         22.         59.\n",
      "  8.         21.         11.          7.66666667  1.3662601   7.\n",
      "  4.        ]\n",
      "[33.         26.          5.         60.         22.         59.\n",
      "  8.         21.         11.          7.66666667  1.3662601   6.\n",
      "  6.        ]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "df2 = pd.read_excel(feature_path)\n",
    "\n",
    "for i in df.index:\n",
    "    is_available = True\n",
    "    skills = []\n",
    "    for name in feature_names:\n",
    "        value = df2[name][i]\n",
    "        if value < 0:\n",
    "            is_available = False\n",
    "            break\n",
    "        skills.append(value)\n",
    "    if not is_available:\n",
    "        continue\n",
    "\n",
    "    for index, q_range in enumerate(questions_ranges):\n",
    "        entry = []\n",
    "        entry.append(skills+depths[index])\n",
    "        entry.append(sub_tests_embed[index])\n",
    "        for j in range(q_range[0],q_range[1]+1):\n",
    "            # add embeddings\n",
    "            detail = []\n",
    "            detail.append(questions_embed[j-1])\n",
    "            detail.append(answers_embed[j-1])\n",
    "            # add cfg depth\n",
    "            new_entry = copy.deepcopy(entry)\n",
    "\n",
    "            new_entry[0] += [questions_depth[j-1],answer_depth[j-1]]\n",
    "            new_entry[0] = np.asarray(new_entry[0])\n",
    "            \n",
    "            if df[f\"Gr{grade}.RC.Gates_\"+\"{:02d}\".format(j)][i] == 1:\n",
    "                detail.append(1)\n",
    "            elif df[f\"Gr{grade}.RC.Gates_\"+\"{:02d}\".format(j)][i] in (2,0):\n",
    "                detail.append(0)\n",
    "            else:\n",
    "                print('DNE')\n",
    "            data.append(new_entry+detail)\n",
    "\n",
    "print(data[0][0])\n",
    "print(data[1][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",'wb') as fp:\n",
    "    pickle.dump(data, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",'rb') as fp:\n",
    "    new_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data[1][0]))\n",
    "# print(len(new_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
