{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",'rb') as fp:\n",
    "    data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = []\n",
    "subtests = []\n",
    "questions = []\n",
    "answers = []\n",
    "y = []\n",
    "for entry in data:\n",
    "    skills.append(entry[0])\n",
    "    subtests.append(entry[1])\n",
    "    questions.append(entry[2])\n",
    "    answers.append(entry[3])\n",
    "    y.append(entry[4])\n",
    "\n",
    "skills = torch.tensor(skills).type(torch.float)\n",
    "subtests = torch.tensor(subtests)\n",
    "questions = torch.tensor(questions)\n",
    "answers = torch.tensor(answers)\n",
    "y = torch.tensor(y).type(torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self, sentence_dim, skill_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc_test = nn.Linear(768,sentence_dim)\n",
    "        self.fc_question = nn.Linear(768,sentence_dim)\n",
    "        self.fc_answer = nn.Linear(768,sentence_dim)\n",
    "        self.fc_skill = nn.Linear(skill_dim,skill_dim*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(3*sentence_dim+skill_dim*2,128)\n",
    "        self.out = nn.Linear(128,1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, skills,test,question,answer):\n",
    "        x1 = self.fc_skill(skills)\n",
    "        x2 = self.fc_test(test)\n",
    "        x3 = self.fc_question(question)\n",
    "        x4 = self.fc_answer(answer)\n",
    "        x = torch.cat((x1,x2,x3,x4),dim=1)\n",
    "        x = self.fc2(self.relu(x))\n",
    "        pred = self.sig(self.out(x))\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. train model\n",
    "max_epochs = 1\n",
    "ep_log_interval = 25\n",
    "lrn_rate = 0.002\n",
    "sentence_dim = 128\n",
    "skill_dim = 9\n",
    "dropout = 0.1\n",
    "\n",
    "net = BertModel(sentence_dim, skill_dim, dropout)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lrn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(data[0],data[1],data[2],data[3]).squeeze(1)\n",
    "    \n",
    "#     print(predictions)\n",
    "\n",
    "    loss = criterion(predictions, data[4])\n",
    "    \n",
    "\n",
    "    acc = binary_accuracy(predictions, data[4])\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "    print(loss)\n",
    "    print(acc)\n",
    "    return loss / len(data[0]), acc / len(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6887, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.5580)\n",
      "\tTrain Loss: 0.000 | Train Acc: 0.01%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    train_loss, train_acc = train(net,[skills,subtests,questions,answers,y],optimizer,criterion)\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
